{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrVwyYKtPt1/X07/r2Eh6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naman-Coder-950/Mini-Project-06/blob/main/Advance_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MK6ReaE_yLOt"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "# Function to generate a random string of a given length\n",
        "def generate_random_string(length=12):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "# Generate 1000 lines of random strings\n",
        "random_strings = [generate_random_string() for _ in range(1000)]\n",
        "\n",
        "# Write to a file\n",
        "with open(\"random_strings_1000.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(random_strings))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=100):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "target_size = 5 * 1024 * 1024  # 5 MB in bytes\n",
        "output_file = \"random_5MB.txt\"\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    total_written = 0\n",
        "    while total_written < target_size:\n",
        "        line = generate_random_string(95) + \"\\n\"  # 95 chars + 1 newline = 96 bytes\n",
        "        f.write(line)\n",
        "        total_written += len(line)\n",
        "\n",
        "# Optionally, print the actual size\n",
        "print(f\"File '{output_file}' created with size: {os.path.getsize(output_file)} bytes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax1vG3B9ym9j",
        "outputId": "57582714-28b7-4649-e584-ea67990be873"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'random_5MB.txt' created with size: 5242944 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=95):\n",
        "    \"\"\"Generates a random string of fixed length.\"\"\"\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "def create_file_with_random_strings(filename, target_size_bytes):\n",
        "    \"\"\"Creates a single file with random strings totaling ~target_size_bytes.\"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        total_written = 0\n",
        "        while total_written < target_size_bytes:\n",
        "            line = generate_random_string() + \"\\n\"\n",
        "            f.write(line)\n",
        "            total_written += len(line)\n",
        "\n",
        "# Parameters\n",
        "num_files = 10\n",
        "target_size = 5 * 1024 * 1024  # 5 MB in bytes\n",
        "\n",
        "# Generate files\n",
        "for i in range(1, num_files + 1):\n",
        "    filename = f\"random_file_{i}.txt\"\n",
        "    create_file_with_random_strings(filename, target_size)\n",
        "    print(f\"Created: {filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2s8f2UgzBOg",
        "outputId": "c77f5834-7111-4b30-806d-53c3b2fd82fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: random_file_1.txt\n",
            "Created: random_file_2.txt\n",
            "Created: random_file_3.txt\n",
            "Created: random_file_4.txt\n",
            "Created: random_file_5.txt\n",
            "Created: random_file_6.txt\n",
            "Created: random_file_7.txt\n",
            "Created: random_file_8.txt\n",
            "Created: random_file_9.txt\n",
            "Created: random_file_10.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=95):\n",
        "    \"\"\"Generate a random string of fixed length (excluding newline).\"\"\"\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "def create_large_file(filename, target_size_bytes):\n",
        "    \"\"\"Creates a file filled with random strings totaling ~target_size_bytes.\"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        total_written = 0\n",
        "        while total_written < target_size_bytes:\n",
        "            line = generate_random_string() + \"\\n\"  # ~96 bytes\n",
        "            f.write(line)\n",
        "            total_written += len(line)\n",
        "    print(f\"Created {filename}: {os.path.getsize(filename) / (1024**3):.2f} GB\")\n",
        "\n",
        "# File sizes in GB\n",
        "sizes_gb = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Create each file\n",
        "for size in sizes_gb:\n",
        "    filename = f\"random_file_{size}GB.txt\"\n",
        "    size_in_bytes = size * 1024**3  # Convert GB to bytes\n",
        "    create_large_file(filename, size_in_bytes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLxkMroxzSFv",
        "outputId": "d4f05cf3-f2f2-49c1-eeee-a9953c3f6a71"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created random_file_1GB.txt: 1.00 GB\n",
            "Created random_file_2GB.txt: 2.00 GB\n",
            "Created random_file_3GB.txt: 3.00 GB\n",
            "Created random_file_4GB.txt: 4.00 GB\n",
            "Created random_file_5GB.txt: 5.00 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def convert_file_to_uppercase(input_file, output_file):\n",
        "    \"\"\"Converts all text in the input file to uppercase and writes to output file.\"\"\"\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            outfile.write(line.upper())\n",
        "    print(f\"Converted: {input_file} ‚Üí {output_file}\")\n",
        "\n",
        "# File sizes to process (in GB)\n",
        "sizes_gb = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Process each file\n",
        "for size in sizes_gb:\n",
        "    input_filename = f\"random_file_{size}GB.txt\"\n",
        "    output_filename = f\"random_file_{size}GB_upper.txt\"\n",
        "    convert_file_to_uppercase(input_filename, output_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwwvXisy02e7",
        "outputId": "1585903a-592a-46fb-b045-f523b690ba25"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted: random_file_1GB.txt ‚Üí random_file_1GB_upper.txt\n",
            "Converted: random_file_2GB.txt ‚Üí random_file_2GB_upper.txt\n",
            "Converted: random_file_3GB.txt ‚Üí random_file_3GB_upper.txt\n",
            "Converted: random_file_4GB.txt ‚Üí random_file_4GB_upper.txt\n",
            "Converted: random_file_5GB.txt ‚Üí random_file_5GB_upper.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def convert_file_to_uppercase(input_file, output_file):\n",
        "    \"\"\"Reads from input_file line by line, converts to uppercase, and writes to output_file.\"\"\"\n",
        "    print(f\"Starting conversion: {input_file}\")\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            outfile.write(line.upper())\n",
        "    print(f\"Finished conversion: {input_file}\")\n",
        "\n",
        "# File sizes to process (in GB)\n",
        "sizes_gb = [1, 2, 3, 4, 5]\n",
        "threads = []\n",
        "\n",
        "# Create and start threads for each file\n",
        "for size in sizes_gb:\n",
        "    input_filename = f\"random_file_{size}GB.txt\"\n",
        "    output_filename = f\"random_file_{size}GB_upper.txt\"\n",
        "    thread = threading.Thread(target=convert_file_to_uppercase, args=(input_filename, output_filename))\n",
        "    thread.start()\n",
        "    threads.append(thread)\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "print(\"All files converted to uppercase.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B3-Qxb-2DlW",
        "outputId": "7bf1ab0c-2fa2-4a42-adb6-f719b206500f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-12 (convert_file_to_uppercase):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-23-411295680>\", line 6, in convert_file_to_uppercase\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'random_file_4GB.txt'\n",
            "Exception in thread Thread-13 (convert_file_to_uppercase):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-23-411295680>\", line 6, in convert_file_to_uppercase\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'random_file_5GB.txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting conversion: random_file_1GB.txtStarting conversion: random_file_2GB.txt\n",
            "Starting conversion: random_file_3GB.txt\n",
            "\n",
            "Starting conversion: random_file_4GB.txt\n",
            "Starting conversion: random_file_5GB.txt\n",
            "Finished conversion: random_file_1GB.txt\n",
            "Finished conversion: random_file_2GB.txt\n",
            "Finished conversion: random_file_3GB.txt\n",
            "All files converted to uppercase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "API_KEY = \"YOUR_API_KEY\"\n",
        "CSE_ID = \"YOUR_CSE_ID\"\n",
        "\n",
        "def google_search(search_term, api_key, cse_id, num=10):\n",
        "    search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
        "    params = {\n",
        "        \"q\": search_term,\n",
        "        \"cx\": cse_id,\n",
        "        \"key\": api_key,\n",
        "        \"searchType\": \"image\",\n",
        "        \"num\": num,\n",
        "    }\n",
        "    response = requests.get(search_url, params=params)\n",
        "    return response.json()\n",
        "\n",
        "def download_images(data, folder=\"cat_images\"):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    for i, item in enumerate(data.get(\"items\", [])):\n",
        "        img_url = item[\"link\"]\n",
        "        try:\n",
        "            img_data = requests.get(img_url).content\n",
        "            with open(os.path.join(folder, f\"cat_{i+1}.jpg\"), \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "            print(f\"Downloaded image {i+1}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not download image {i+1}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = google_search(\"cat\", API_KEY, CSE_ID, num=10)\n",
        "    download_images(results)\n"
      ],
      "metadata": {
        "id": "IdTZCtUQ6qyg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjDXQMVgHRI9",
        "outputId": "12c032c5-9fa1-4152-d17c-796e0993f368"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import Search, YouTube\n",
        "import os\n",
        "\n",
        "SEARCH_QUERY = \"Machine Learning\"\n",
        "MAX_VIDEOS = 10\n",
        "DOWNLOAD_FOLDER = \"ml_videos_pytube\"\n",
        "\n",
        "def download_videos():\n",
        "    if not os.path.exists(DOWNLOAD_FOLDER):\n",
        "        os.makedirs(DOWNLOAD_FOLDER)\n",
        "\n",
        "    search = Search(SEARCH_QUERY)\n",
        "    videos = search.results[:MAX_VIDEOS]\n",
        "\n",
        "    for i, video in enumerate(videos):\n",
        "        try:\n",
        "            print(f\"Downloading {i+1}: {video.title}\")\n",
        "            stream = video.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "            stream.download(DOWNLOAD_FOLDER)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_videos()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eT2x2ybHY20",
        "outputId": "bac59e7f-295d-4dfb-9dd4-2626b7beebc9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n",
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n",
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n",
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n",
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1: Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 2: Machine Learning Explained in 100 Seconds\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 3: Machine Learning for Everybody ‚Äì Full Course\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 4: Complete Machine Learning In 6 Hours| Krish Naik\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 5: Ensemble Learning in Machine Learning‚Äã | Decision Tree & Random Forest | Machine Learning Tutorial\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 6: Stanford CS229 I Machine Learning I Building Large Language Models (LLMs)\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 7: Essential Machine Learning and AI Concepts Animated\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 8: All Machine Learning algorithms explained in 17 min\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 9: Machine Learning Full Course - Learn Machine Learning 10 Hours | Machine Learning Tutorial | Edureka\n",
            "Failed to download: HTTP Error 400: Bad Request\n",
            "Downloading 10: 11. Introduction to Machine Learning\n",
            "Failed to download: HTTP Error 400: Bad Request\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yt-dlp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxhBBoB0IVng",
        "outputId": "c801a32f-9c53-44f7-d34e-acf330561164"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.6.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Folder to save audio files\n",
        "AUDIO_FOLDER = \"ml_audio\"\n",
        "os.makedirs(AUDIO_FOLDER, exist_ok=True)\n",
        "\n",
        "# List of 10 YouTube video URLs (replace or add more as needed)\n",
        "video_urls = [\n",
        "    \"https://www.youtube.com/watch?v=GwIo3gDZCVQ\",\n",
        "    \"https://www.youtube.com/watch?v=aircAruvnKk\",\n",
        "    \"https://www.youtube.com/watch?v=KTeVOb8gaD4\",\n",
        "    \"https://www.youtube.com/watch?v=1vsmaEfbnoE\",\n",
        "    \"https://www.youtube.com/watch?v=8rXD5-xhemo\",\n",
        "    \"https://www.youtube.com/watch?v=ukzFI9rgwfU\",\n",
        "    \"https://www.youtube.com/watch?v=i_LwzRVP7bg\",\n",
        "    \"https://www.youtube.com/watch?v=4b5d3muPQmA\",\n",
        "    \"https://www.youtube.com/watch?v=Gv9_4yMHFhI\"\n",
        "]\n",
        "\n",
        "# Function to convert video to audio\n",
        "def convert_to_audio(url):\n",
        "    try:\n",
        "        command = [\n",
        "            \"yt-dlp\",\n",
        "            \"--extract-audio\",\n",
        "            \"--audio-format\", \"mp3\",\n",
        "            \"--output\", os.path.join(AUDIO_FOLDER, \"%(title)s.%(ext)s\"),\n",
        "            url\n",
        "        ]\n",
        "        subprocess.run(command, check=True)\n",
        "        print(f\"‚úÖ Converted: {url}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Error converting {url}: {e}\")\n",
        "\n",
        "# Process all videos\n",
        "def main():\n",
        "    print(f\"üîÑ Starting conversion of {len(video_urls)} videos to MP3...\")\n",
        "    for url in video_urls:\n",
        "        convert_to_audio(url)\n",
        "    print(f\"\\nüéâ All videos converted. Files saved in '{AUDIO_FOLDER}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAa44orBOg-t",
        "outputId": "6a13a358-24cd-4d57-a4e9-f6c16e5be322"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting conversion of 9 videos to MP3...\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=GwIo3gDZCVQ\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=aircAruvnKk\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=KTeVOb8gaD4\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=1vsmaEfbnoE\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=8rXD5-xhemo\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=ukzFI9rgwfU\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=i_LwzRVP7bg\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=4b5d3muPQmA\n",
            "‚úÖ Converted: https://www.youtube.com/watch?v=Gv9_4yMHFhI\n",
            "\n",
            "üéâ All videos converted. Files saved in 'ml_audio'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import concurrent.futures\n",
        "from time import time\n",
        "\n",
        "# Folder to save audio files\n",
        "DOWNLOAD_FOLDER = \"yt_audio_100\"\n",
        "MAX_THREADS = 8  # You can increase this based on your system capability\n",
        "\n",
        "# List of YouTube video URLs (100 video links can go here)\n",
        "video_urls = [\n",
        "    # -- Add your 100 video links below --\n",
        "    \"https://www.youtube.com/watch?v=Gv9_4yMHFhI\",\n",
        "    \"https://www.youtube.com/watch?v=ukzFI9rgwfU\",\n",
        "    # ... up to 100 links\n",
        "]\n",
        "\n",
        "# Ensure output directory exists\n",
        "if not os.path.exists(DOWNLOAD_FOLDER):\n",
        "    os.makedirs(DOWNLOAD_FOLDER)\n",
        "\n",
        "# Function to download and convert a single video\n",
        "def process_video(url):\n",
        "    try:\n",
        "        print(f\"Starting download: {url}\")\n",
        "        command = [\n",
        "            \"yt-dlp\",\n",
        "            \"--extract-audio\",\n",
        "            \"--audio-format\", \"mp3\",\n",
        "            \"-o\", os.path.join(DOWNLOAD_FOLDER, \"%(title)s.%(ext)s\"),\n",
        "            url\n",
        "        ]\n",
        "        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        return f\"‚úÖ Success: {url}\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Failed: {url} | Error: {e}\"\n",
        "\n",
        "# Main function to run multithreaded pipeline\n",
        "def run_pipeline(urls):\n",
        "    start_time = time()\n",
        "    print(f\"\\nüöÄ Starting download/conversion of {len(urls)} videos...\\n\")\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
        "        results = list(executor.map(process_video, urls))\n",
        "\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    print(f\"\\n‚úÖ All tasks completed in {round(time() - start_time, 2)} seconds.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline(video_urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHeyb9NdJPGz",
        "outputId": "6cb7c83e-df17-41c3-b74b-be538d905bde"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting download/conversion of 2 videos...\n",
            "\n",
            "Starting download: https://www.youtube.com/watch?v=Gv9_4yMHFhI\n",
            "Starting download: https://www.youtube.com/watch?v=ukzFI9rgwfU\n",
            "‚úÖ Success: https://www.youtube.com/watch?v=Gv9_4yMHFhI\n",
            "‚úÖ Success: https://www.youtube.com/watch?v=ukzFI9rgwfU\n",
            "\n",
            "‚úÖ All tasks completed in 9.9 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install icrawler pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGPCrnC5JSrC",
        "outputId": "290cb157-9e9b-4336-8e26-59d065babc5f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (4.13.4)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from icrawler) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2025.4.26)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Settings\n",
        "NUM_IMAGES = 500\n",
        "MAX_THREADS = 8\n",
        "INPUT_FOLDER = 'dog_images_raw'\n",
        "OUTPUT_FOLDER = 'dog_images_rescaled'\n",
        "\n",
        "# Step 1: Download images using icrawler\n",
        "def download_images():\n",
        "    if not os.path.exists(INPUT_FOLDER):\n",
        "        os.makedirs(INPUT_FOLDER)\n",
        "\n",
        "    print(f\"üì• Downloading {NUM_IMAGES} dog images...\")\n",
        "    crawler = GoogleImageCrawler(storage={'root_dir': INPUT_FOLDER})\n",
        "    crawler.crawl(keyword='dog', max_num=NUM_IMAGES, file_idx_offset=0)\n",
        "\n",
        "# Step 2: Rescale image to 50%\n",
        "def rescale_image(img_path):\n",
        "    try:\n",
        "        with Image.open(img_path) as img:\n",
        "            new_size = (img.width // 2, img.height // 2)\n",
        "            img_resized = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "            if not os.path.exists(OUTPUT_FOLDER):\n",
        "                os.makedirs(OUTPUT_FOLDER)\n",
        "\n",
        "            base_name = os.path.basename(img_path)\n",
        "            output_path = os.path.join(OUTPUT_FOLDER, base_name)\n",
        "            img_resized.save(output_path)\n",
        "            return f\"‚úÖ Rescaled: {base_name}\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Failed: {img_path} | Error: {e}\"\n",
        "\n",
        "# Multithreaded rescaling\n",
        "def rescale_all_images():\n",
        "    image_files = glob(os.path.join(INPUT_FOLDER, '*'))\n",
        "    print(f\"üìè Rescaling {len(image_files)} images to 50%...\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
        "        for result in tqdm(executor.map(rescale_image, image_files), total=len(image_files)):\n",
        "            pass  # tqdm handles progress; remove 'pass' to print result logs if needed\n",
        "\n",
        "# Main pipeline\n",
        "def main():\n",
        "    download_images()\n",
        "    rescale_all_images()\n",
        "    print(f\"\\nüéâ Done! Images saved in '{OUTPUT_FOLDER}'.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB7iKGPmL0tV",
        "outputId": "96f1461f-3629-48c8-b443-a744405a581d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading 500 dog images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread parser-001:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/icrawler/parser.py\", line 93, in worker_exec\n",
            "    for task in self.parse(response, **kwargs):\n",
            "TypeError: 'NoneType' object is not iterable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìè Rescaling 1 images to 50%...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 2187.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéâ Done! Images saved in 'dog_images_rescaled'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}